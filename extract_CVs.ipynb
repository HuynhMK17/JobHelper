{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LLAMA_3_API_KEY = os.getenv(\"LLAMA_3_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Năm 3 - HK1\\DoAnCS311\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:362: UserWarning: WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=LLAMA_3_API_KEY,\n",
    "    model_name=\"llama-3.1-70b-versatile\",\n",
    "    seed=42  # Đặt seed để đảm bảo kết quả luôn giống nhau\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, EmailStr, field_validator\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "# ForgivingDate model with date validation\n",
    "class ForgivingDate(BaseModel):\n",
    "    day: int\n",
    "    month: int\n",
    "    year: int\n",
    "\n",
    "    @field_validator('day')\n",
    "    def day_validator(cls, v):\n",
    "        if v == None:\n",
    "            v = None\n",
    "        if v > 31 or v < 0:\n",
    "            raise ValueError(\"Day not in range\")\n",
    "        return v\n",
    "\n",
    "    @field_validator('month')\n",
    "    def month_validator(cls, v):\n",
    "        if v == None:\n",
    "            v = None\n",
    "            \n",
    "        if v > 12 or v < 0:\n",
    "            raise ValueError(\"Month not in range\")\n",
    "    \n",
    "        return v\n",
    "\n",
    "# Contact model with email validation\n",
    "class Contact(BaseModel):\n",
    "    name: str\n",
    "    phone_number: str\n",
    "    email: Optional[str] = Field(None, description=\"Email address\")\n",
    "    linkedin: str\n",
    "    location: str = Field(\n",
    "        default_factory=str,\n",
    "        description=\"Complete street address wherever possible.\"\n",
    "    )\n",
    "\n",
    "class Role(BaseModel):\n",
    "    name: str = Field(description=\"The position the candidate is applying for\")\n",
    "    num_experience: float = Field(description='Years of experience deducted from the (number of days between the dates)/365 in title \"Kinh nghiệm\"')\n",
    "\n",
    "# # DateRange model containing start and end dates\n",
    "# class DateRange(BaseModel):\n",
    "#     start: ForgivingDate\n",
    "#     end: ForgivingDate = Field(description=\"Date of the end\", default=ForgivingDate(day=date.today().day, month=date.today().month, year=date.today().year))\n",
    "\n",
    "# Skills model with various fields for skills information\n",
    "# class Skills(BaseModel):\n",
    "#     name: str = Field(description=\"Extract the technical tools in the following text. Technical tools are generally in 2-3 words\")\n",
    "\n",
    "# class Major(BaseModel):\n",
    "#     name: str = Field(description=\"The major of the candidate\")\n",
    "\n",
    "# # Experience model containing details about work experiences\n",
    "# class Experience(BaseModel):\n",
    "#     dates: DateRange\n",
    "#     title: str = Field(description=\"Title of the role\")\n",
    "#     num_experience: float = Field(description='Years of experience deducted from the (number of days between the dates)/365')\n",
    "#     company: str = Field(description=\"The employer\")\n",
    "#     skills: List[Skills]\n",
    "#     description: str = Field(description=\"Detailed description of the experience\")\n",
    "\n",
    "# Education model for education details\n",
    "# class Education(BaseModel):\n",
    "#     college: str = Field(description='Institution from which the person received their degree')\n",
    "#     dates: DateRange\n",
    "\n",
    "# Project model to capture project details\n",
    "# class Project(BaseModel):\n",
    "#     dates: DateRange\n",
    "#     title: str = Field(description=\"Title of the role\")\n",
    "#     num_experience: float = Field(description='Years of experience deducted from the (number of days between the dates)/365')\n",
    "#     name_project: str = Field(description=\"Name of the project\")\n",
    "#     skills: List[Skills]\n",
    "#     description: str = Field(description=\"Detailed description of the project\")\n",
    "\n",
    "# class CertificateAward(BaseModel):\n",
    "#     name: str = Field(description=\"The name of the certificate or award\")\n",
    "#     issuing_organization: str = Field(description=\"The organization that issued the certificate or award\")\n",
    "\n",
    "\n",
    "# Candidate model containing all information about the candidate\n",
    "class Candidate(BaseModel):\n",
    "    contact: Contact\n",
    "    role: List[Role] = Field(description=\"The position the candidate is applying for\")\n",
    "    skills: List[str] = Field(description=\"Extract the technical tools in the following text. Technical tools are generally in 2-3 words\")\n",
    "    major: List[str] = Field(description=\"The major of the candidate\")    \n",
    "    # programming_language: List[str] = Field(description=\"The programming language\")\n",
    "    # language: List[str] = Field(description=\"The spoken/written language\")\n",
    "    # tool: List[str] = Field(description=\"Technical tool, generally in 2-3 words.\")\n",
    "    # soft_skills: List[str] = Field(description=\"Name of the soft skills\")\n",
    "    \n",
    "    # education: List[Education]\n",
    "    # experience: List[Experience]\n",
    "    # projects: List[Project]\n",
    "    \n",
    "    # certificates: List[CertificateAward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Candidate)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Extract the following structured information from the provided CV text. If information is missing, leave it blank. \n",
    "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
    "     input_variables=[\"query\"],\n",
    "     partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'\\n%PDF'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "     r'F:\\Năm 3 - HK1\\DoAnCS311\\data\\Temp\\3.pdf'\n",
    ")\n",
    "pages = []\n",
    "text = \"\"\n",
    "for doc in loader.lazy_load():\n",
    "     pages.append(doc)\n",
    "     text += doc.page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'F:\\\\Năm 3 - HK1\\\\DoAnCS311\\\\data\\\\Temp\\\\3.pdf', 'page': 0}, page_content='User 1\\nAI ENGINEER\\nTHÔNG TIN CÁ NHÂN\\n\\ue11b 0935123456\\n✉ nguyenduytamanh@example.\\ncom\\n\\uf05a https://github.com/tamchamch\\ni \\n\\uf3c5 Th ủ  Đ ứ c, H ồ  Chí Minh\\nCÁC K Ỹ  N Ă NG\\nK Ĩ  N Ă NG CHUYÊN MÔN\\n•Thành th ạ o: Python, \\nTensorFlow, PyTorch, Scikit-\\nlearn, Hugging Face\\n•X ử  lý d ữ  li ệ u: Pandas, NumPy, \\nMongoDB\\n•Hi ể u bi ế t: Machine Learning, \\nNLP, Computer Vision, Multi-\\nmodal Learning \\nK Ĩ  N Ă NG M Ề M\\n•Giao ti ế p và làm vi ệ c nhóm hi ệ u \\nqu ả \\n•Qu ả n lý th ờ i gian t ố t\\n•K ỹ  n ă ng gi ả i quy ế t v ấ n đ ề  \\nTHÔNG TIN THÊM\\nM Ụ C TIÊU NGH Ề  NGHI Ệ P\\n- Phát tri ể n và đ óng góp trong l ĩ nh v ự c AI, đ ặ c bi ệ t là Machine Learning và NLP. - - - \\nH ư ớ ng đ ế n tr ở  thành AI Engineer chuyên nghi ệ p, t ố i ư u hóa các gi ả i pháp công ngh ệ  \\nph ụ c v ụ  doanh nghi ệ p và xã h ộ i. \\nKINH NGHI Ệ M LÀM VI Ệ C\\nTh ự c t ậ p sinh AI Engineer 06/2024 - 09/2024\\nCông ty XYZ \\n•Phát tri ể n mô hình phân lo ạ i c ả m xúc v ớ i T5-base \\x00ne-tuning. \\n•Tích h ợ p h ệ  th ố ng qu ả n lý mô hình b ằ ng Weights & Biases.\\n•C ả i thi ệ n đ ộ  chính xác mô hình lên 85% thông qua k ỹ  thu ậ t t ă ng c ư ờ ng d ữ  li ệ u \\nvà tinh ch ỉ nh tham s ố . \\nC ộ ng tác viên Data Science 03/2023 - 05/2024 \\nT ậ p đ oàn ABC \\n•Xây d ự ng pipeline x ử  lý d ữ  li ệ u l ớ n v ớ i MongoDB và Python. \\n•Phân tích d ữ  li ệ u khách hàng và tri ể n khai thu ậ t toán d ự  đ oán hành vi. \\nH Ọ C V Ấ N\\nKHOA H Ọ C MÁY TINH 9/2022 - Hi ệ n nay\\nTr ư ờ ng Đ ạ i h ọ c Công Ngh ệ  Thông Tin - Đ HQG HCM\\nGPA: 3.2/4\\nDANH HI Ệ U VÀ GI Ả I TH Ư Ở NG\\nCH Ứ NG CH Ỉ \\n06/2024\\nMachine Learning Specialization (Coursera, c ấ p b ở i Stanford University) \\n06/2024 Python for Data Science (IBM) \\n05/2024 Advanced NLP Techniques (Hugging Face) \\nHO Ạ T Đ Ộ NG\\n-\\nD Ự  ÁN\\nLEAD DEVELOPER\\nMulti-modal Sarcasm Detection 10/2024 - 11/2024\\n \\nS ố  l ư ợ ng ng ư ờ i tham gia 5\\nPython, PyTorch, Hugging Face, CLIP \\nK ế t h ợ p v ă n b ả n và hình ả nh đ ể  phát hi ệ n châm bi ế m, s ử  d ụ ng các ph ư ơ ng pháp \\nfusion nh ư  early và hybrid. '),\n",
       " Document(metadata={'source': 'F:\\\\Năm 3 - HK1\\\\DoAnCS311\\\\data\\\\Temp\\\\3.pdf', 'page': 1}, page_content='V ị  trí\\nBackend Developer \\nCandidate Management System 2/2024 - 4/2024\\n  \\nS ố  l ư ợ ng ng ư ờ i tham gia 3\\nDjango, MongoDB \\nH ệ  th ố ng qu ả n lý ứ ng viên, tích h ợ p các danh m ụ c k ỹ  n ă ng và phân tích d ữ  li ệ  \\n \\n \\n© topcv.vn')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contact': {'name': 'Nguyen Duy Tam Anh',\n",
       "  'phone_number': '0935123456',\n",
       "  'email': 'nguyenduytamanh@example.com',\n",
       "  'linkedin': '',\n",
       "  'location': 'Thủ Đức, Hồ Chí Minh'},\n",
       " 'role': [{'name': 'AI ENGINEER', 'num_experience': 0}],\n",
       " 'skills': ['Python',\n",
       "  'TensorFlow',\n",
       "  'PyTorch',\n",
       "  'Scikit-learn',\n",
       "  'Hugging Face',\n",
       "  'Pandas',\n",
       "  'NumPy',\n",
       "  'MongoDB',\n",
       "  'Machine Learning',\n",
       "  'NLP',\n",
       "  'Computer Vision',\n",
       "  'Multi-modal Learning',\n",
       "  'Django',\n",
       "  'CLIP'],\n",
       " 'major': ['KHOA HỆC MÁY TINH']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke({\"query\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Gọi chuỗi chain.invoke và lưu kết quả\n",
    "result = chain.invoke({\"query\": text})\n",
    "\n",
    "# Chuyển kết quả thành một DataFrame (giả sử kết quả là một từ điển hoặc chuỗi)\n",
    "if isinstance(result, dict):\n",
    "    df = pd.DataFrame([result])  # Nếu là dict, chuyển đổi sang DataFrame\n",
    "elif isinstance(result, str):\n",
    "    df = pd.DataFrame([{\"response\": result}])  # Nếu là chuỗi, gói trong một cột 'response'\n",
    "else:\n",
    "    raise ValueError(\"Result format not supported\")\n",
    "\n",
    "# Lưu vào tệp CSV\n",
    "output_file = \"output.csv\"\n",
    "df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Result saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'experience'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Năm 3 - HK1\\DoAnCS311\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'experience'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mf:\\Năm 3 - HK1\\DoAnCS311\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\Năm 3 - HK1\\DoAnCS311\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'experience'"
     ]
    }
   ],
   "source": [
    "df['experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
